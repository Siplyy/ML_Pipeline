# Документация пайплайна для classic ML
## Идея
Во всех крупных компаниях стремятся оптимизировать процесс обучения моделей настолько, насколько это возможно. Для этого и придумали систему пайлпайнов - автоматизированного помощника для Data Scientista. Нам же данная система интересна как pet project позволяющий затронуть некоторые из основных этапов DS специалиста, а также подготовить почву для участия в хакатонах, что позволит нам больше времени уделять на решение самой задачи, а не написание однотипного кода
## Основные разделы
### EDA
Раздел для автоматического проведения разведочного анализа данных. Включает в себя: функции для разбиения признаков по типам данных, построения 
графиков для изучения распределений, а также базовых функций для обработки выбросов
### Первоначальный отбор признако
Содержит в себе фунцкии, позволяющие отбросить очевидно посторонние признаки:
- Отбрасываем признаки, содержащие количество пропусков, превышающее заданный порог
- Выделяем в отдельный список признаки, которые содержат количество уникальных значений больше заданного порога (позволяет найти признаки типа даты,
id пользователя и другие признаки, не используемые для обучения модели)
### Кодирование признаков и нормализация признаков
На этом этапе пользователь должен определить списки признаков, которые необходимо закодировать/нормализовать
- One hot encoder
- Label encoder
- Несколько видов нормализации
### Заполнение пропусков
- Различные вариации заполнения пропусков: Средним, медианой, модой, каким-то определенным значением (более актуально для решений основанных на деревьях)
### Feature engeneering
- Простейшие функции для создания фичей на основе имеющихся (сумма, разность, частное, произведение, среднее)
- Создание новых фичей на основе моделей кластеризации?
### Балансировка классов
- С помощью выделения лишь части датасета 
- С помощью генерации искуственных объектов
### Отбор фичей
- Отбор по корреляции
- Отбор по шапам (библиотека shaps) top_k/с значениями shap находящимися ниже заданного порога
- Отбор признаков по падению целевой метрики (убираем признак, обучаем модель без него, смотрим как изменилась значение целевой метрики, принимаем решение)
- Забыл как называется, суть в том, что мы перемешиваем значения внутри признака, и аналогично предыдущему сверяем значения целевой метрики до шаффла и после, принимаем решение
### Разбиение датасета для обучения:
- Train/test
- Train/test/val
- Разбиение по временным промежуктам
### Обучение модели
На выбор должно быть предоставлено несколько различных моделей машинного обучения в зависимости от задачи (классификация/регрессия)
- Линрег
- Логрег
- Случайный лес
- Градиентный бустинг в имплементации от LightGBM, XGBoost, Catboost
